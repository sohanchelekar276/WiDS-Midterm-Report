{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNO4+zfGWx6AZlOQSRspwz0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sohanchelekar276/WiDS-Midterm-Report/blob/main/WiDS_Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjS0hxj753LQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Make plots look nicer\n",
        "sns.set_theme(style=\"whitegrid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: Introduction to Exploratory Data Analysis (EDA)\n",
        "Step 1: Load the Data Note: Let it be named spotify_data.csv"
      ],
      "metadata": {
        "id": "m-ozxxG96kN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv('spotify_data.csv')"
      ],
      "metadata": {
        "id": "SL9wfkkz6tZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(a) Display first and last 5 rows"
      ],
      "metadata": {
        "id": "EZ1DL_pZ6yW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"First 5 rows:\")\n",
        "display(df.head())\n",
        "\n",
        "print(\"\\nLast 5 rows:\")\n",
        "display(df.tail())"
      ],
      "metadata": {
        "id": "XJdp5qOy63QY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(b) Print dataset shape and column names"
      ],
      "metadata": {
        "id": "boFO1skd67H5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape of dataset: {df.shape}\")\n",
        "print(f\"Column Names: {df.columns.tolist()}\")"
      ],
      "metadata": {
        "id": "Tw2z_AzW7AJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(c) Use info() and describe()"
      ],
      "metadata": {
        "id": "ROByGOyx7F3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Info ---\")\n",
        "df.info()\n",
        "\n",
        "print(\"\\n--- Statistical Summary ---\")\n",
        "display(df.describe())"
      ],
      "metadata": {
        "id": "E8zqmLBL7H8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(d) Identify numerical and categorical columns"
      ],
      "metadata": {
        "id": "VF5EoaUT7J5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "print(f\"Numerical Columns: {numerical_cols}\")\n",
        "print(f\"Categorical Columns: {categorical_cols}\")"
      ],
      "metadata": {
        "id": "TdaICiQ97QLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: Handling Missing Values & Feature Scaling\n",
        "\n",
        "(a) & (b) Check and Handle Missing Values"
      ],
      "metadata": {
        "id": "15q0Q3fY7XEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(\"Missing values before cleaning:\\n\", df.isnull().sum())\n",
        "\n",
        "# Handling them: We usually drop rows with missing values for simple assignments\n",
        "df_clean = df.dropna().copy()\n",
        "\n",
        "print(\"Missing values after cleaning:\\n\", df_clean.isnull().sum())"
      ],
      "metadata": {
        "id": "GGzmRKoP7cd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(c) Select numerical features"
      ],
      "metadata": {
        "id": "z3EK0rNw7sTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['danceability', 'energy', 'loudness', 'tempo', 'valence']\n",
        "X = df_clean[features]"
      ],
      "metadata": {
        "id": "wCDMx4LZ7uiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(d) Apply Standardization Standardization rescales data so it has a mean of 0 and a standard deviation of 1. Crucial for models like Logistic Regression."
      ],
      "metadata": {
        "id": "ll8AmpBt7vum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Convert back to dataframe for easier viewing later\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=features)\n",
        "print(\"First 5 rows of scaled data:\")\n",
        "display(X_scaled_df.head())"
      ],
      "metadata": {
        "id": "7P9JBO0A70Z2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(e) Explain Normalization vs Standardization\n",
        "\n",
        "Normalization (Min-Max Scaling): Squishes all data points into a fixed range, usually between 0 and 1. Useful when you need positive values or strictly bounded data (like for neural networks or image processing).\n",
        "\n",
        "Standardization (Z-score): Centers the data around 0. It doesn't enforce a strict limit (e.g., you can have a value of 3.5), but it handles outliers better. It is generally preferred for algorithms that assume a \"bell curve\" distribution (like Logistic Regression)."
      ],
      "metadata": {
        "id": "menUhxfP74qY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: Data Visualization for EDA\n",
        "(a) Histogram of danceability"
      ],
      "metadata": {
        "id": "gJcu5ydc8Gy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(df_clean['danceability'], kde=True, color='skyblue')\n",
        "plt.title('Distribution of Danceability')\n",
        "plt.xlabel('Danceability Score')\n",
        "plt.show()\n",
        "# Observation: The data looks fairly normal, slightly skewed towards higher danceability."
      ],
      "metadata": {
        "id": "VWflc70V8MdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(b) Boxplot of energy"
      ],
      "metadata": {
        "id": "vJNarYzc8cxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "sns.boxplot(x=df_clean['energy'], color='lightgreen')\n",
        "plt.title('Boxplot of Energy')\n",
        "plt.show()\n",
        "# Observation: Check if there are dots outside the \"whiskers\"—those are outliers."
      ],
      "metadata": {
        "id": "QmCeqTWs8ge1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(c) Scatter plot: energy vs loudness"
      ],
      "metadata": {
        "id": "GF7T2Gup8jHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "# Calculating correlation only on numerical columns\n",
        "corr = df_clean[features].corr()\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Feature Correlation Heatmap')\n",
        "plt.show()\n",
        "# Observation: Look for dark red squares. Energy and Loudness often have a high correlation coefficient (near 0.7 or 0.8)."
      ],
      "metadata": {
        "id": "P0SLE5jX8nOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(d) Correlation heatmap"
      ],
      "metadata": {
        "id": "si2iQsI68s6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "# Calculating correlation only on numerical columns\n",
        "corr = df_clean[features].corr()\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Feature Correlation Heatmap')\n",
        "plt.show()\n",
        "# Observation: Look for dark red squares. Energy and Loudness often have a high correlation coefficient (near 0.7 or 0.8)."
      ],
      "metadata": {
        "id": "YmCdyP3T84ZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: Audio Features & Mood\n",
        "(a) Explain danceability, energy, valence\n",
        "\n",
        "Danceability: Describes how suitable a track is for dancing based on tempo, rhythm stability, and beat strength. High value = very danceable.\n",
        "\n",
        "Energy: A measure of intensity and activity. Energetic tracks feel fast, loud, and noisy (e.g., Death Metal is high energy, Bach is low).\n",
        "\n",
        "Valence: A measure of musical \"positiveness.\" High valence sounds happy/cheerful; low valence sounds sad/depressed.\n",
        "\n",
        "(b) Identify features related to happy or energetic music\n",
        "\n",
        "Happy Music: High Valence (the primary indicator) and typically high Danceability.\n",
        "\n",
        "Energetic Music: High Energy, high Loudness, and often faster Tempo."
      ],
      "metadata": {
        "id": "BsdEhtN386ZI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: Supervised Learning – Classification\n",
        "(a) Create mood column We will create a binary target variable: 1 for \"Happy\" (High Valence) and 0 for \"Sad\" (Low Valence). Let's use 0.5 as the cutoff."
      ],
      "metadata": {
        "id": "6dbc2sEi9aVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 if valence > 0.5, else 0\n",
        "y = (df_clean['valence'] > 0.5).astype(int)\n",
        "\n",
        "print(\"Class distribution:\")\n",
        "print(y.value_counts())"
      ],
      "metadata": {
        "id": "sOW9eVK99KQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(b) Train-test split (80-20)"
      ],
      "metadata": {
        "id": "jGZfPiTr9XsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_scaled was created in Q2 (d)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "UV1v9UTo9jlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(c) Train Logistic Regression"
      ],
      "metadata": {
        "id": "H0VvAoqR9mx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "c0JtUCkl9pHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(d) Evaluate Results"
      ],
      "metadata": {
        "id": "hE0oQubO9qyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = log_reg.predict(X_test)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {acc:.2f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Observation: The model tries to predict mood based on energy/danceability.\n",
        "# Accuracy might be modest because mood is complex!"
      ],
      "metadata": {
        "id": "PgW5SLe29s21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6: Bonus (Compare with KNN)\n",
        "Let's try K-Nearest Neighbors to see if it performs better."
      ],
      "metadata": {
        "id": "DAJf1e-39xqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize KNN classifier (let's try k=5 neighbors)\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "acc_knn = accuracy_score(y_test, y_pred_knn)\n",
        "print(f\"KNN Accuracy: {acc_knn:.2f}\")\n",
        "\n",
        "if acc_knn > acc:\n",
        "    print(\"Observation: KNN performed better than Logistic Regression.\")\n",
        "else:\n",
        "    print(\"Observation: Logistic Regression performed better (or similar) to KNN.\")"
      ],
      "metadata": {
        "id": "OKJwsO7_9ye3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}